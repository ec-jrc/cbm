{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JRC Sample Extraction\n",
    "<div>\n",
    "<img src=\"jrc_ec_logo.jpg\" width=\"400\"/>\n",
    "</div>\n",
    "\n",
    "Solution that selects inspection samples for the quality assessments (QA) of the Area Monitoring System (AMS) and GeoSpatial Application (GSA) \n",
    "\n",
    "[INTRODUCTION + GENERAL INSTRUCTIONS HERE]\n",
    "\n",
    "Authors: Fernando Fahl (fernando.fahl@ext.ec.europa.eu), Mateusz Dobrychłop (mateusz.dobrychlop@ext.ec.europa.eu), Ferdinando Urbano (ferdinando.urbano@ec.europa.eu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parcel list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to display a set of widgets that will allow you to select your input file.\n",
    "\n",
    "[INSTRUCTIONS + PARCEL FILE FORMATTING HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .info-button-style {\n",
       "        border-radius: 50%;  /* Makes the button circular */\n",
       "    }\n",
       "    .info-button-style:hover {\n",
       "        box-shadow: none !important;  /* Removes shadow on hover */\n",
       "        transform: none !important;  /* Stops any popping or scaling */\n",
       "        cursor: default;  /* Removes the hand cursor */\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af0895f0f824be2855a26d6ce7ab758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(icon='info', layout=Layout(width='30px'), style=ButtonStyle(), tooltip='T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sample_extraction_gui as gui\n",
    "uploaded_files = gui.display_parcel_input_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define bucket targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to display a set of widgets that will allow you to define ua group bucket targets.\n",
    "\n",
    "[INSTRUCTIONS + TARGET FILE FORMATTING HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f53009367aa42ea9f5e93a6dfabba0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(icon='info', layout=Layout(width='30px'), style=ButtonStyle(), tooltip='Y…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gui.display_bucket_targets_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set output and optional parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[INSTRUCTIONS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e215aaa12194c66be686c87b880267b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Checkbox(value=True, description='Prioritize parcels of a holding until a limit …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gui.display_advanced_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[INSTRUCTIONS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocodish code that makes it easy to follow the algorithm workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import cosmetics_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction and output writing functions\n",
    "\n",
    "Processing of two key input files:\n",
    " - the ranked \"interventions\" csv file, that contains rows corresponding to intervention types associated with parcels, which are associated with holdings\n",
    " - the \"targets\" csv file, listing target parcel count for each bucket corresponding to a single intervention type\n",
    "\n",
    " The intervention file is transformed into a DataFrame (filtering out some of its columns) and then used as the main data structure that is iterated over.\n",
    " The intervention DataFrame is sorted by the \"ranking\" column.\n",
    "\n",
    " The targets file is used to create a dictionary that represents buckets, that is gradually populated with info from the intervention DataFrame.\n",
    "\n",
    " This cell also defines a simple function that saves an output excel file.\n",
    "\n",
    " **TODO: Probably instead of just adding a row to a bucket, I should also implement a loop through all rows of a parcel.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interventions(path):\n",
    "    \"\"\"\n",
    "    Extracts the interventions from the csv file and returns a dataframe with the columns:\n",
    "    - parcel_id\n",
    "    - holding_id\n",
    "    - intervention_type_id\n",
    "    - ranking\n",
    "    \"\"\"\n",
    "    interventions_full_df = pd.read_csv(path)\n",
    "    # filter donw to take only rows where covered = 1\n",
    "    interventions_full_df = interventions_full_df[interventions_full_df[\"covered\"] == 1]\n",
    "    interventions_df = interventions_full_df[[\"gsa_par_id\", \"gsa_hol_id\", \"ua_grp_id\", \"ranking\"]]\n",
    "    interventions_df = interventions_df.sort_values(by=\"ranking\")\n",
    "    interventions_df = interventions_df.rename(columns={\"ua_grp_id\": \"intervention_type_id\", \n",
    "                                                        \"gsa_hol_id\": \"holding_id\", \n",
    "                                                        \"gsa_par_id\": \"parcel_id\"})\n",
    "    \n",
    "    # add a unique row id column that is combination of parcel_id, holding_id and intervention_type_id\n",
    "    # this will be used to identify which rows were already added to buckets\n",
    "    interventions_df['row_id'] = interventions_df['parcel_id'].astype(str) + interventions_df['holding_id'].astype(str) + interventions_df['intervention_type_id'].astype(str)\n",
    "    interventions_df['order_added'] = 0\n",
    "\n",
    "\n",
    "    return interventions_df\n",
    "\n",
    "def buckets_global_count(buckets):\n",
    "    \"\"\"\n",
    "    Returns a number of rows already added to all buckets together\n",
    "    \"\"\"\n",
    "    return sum([len(bucket['parcels']) for bucket in buckets.values()])\n",
    "\n",
    "def extract_buckets(path):\n",
    "    \"\"\"\n",
    "    Extracts the targets from the csv file and returns a dictionary with the keys being the intervention_type_id\n",
    "    and the values being a dictionary with the keys:\n",
    "    - target: the target number of parcels\n",
    "    - parcels: a list of dictionaries with the keys:\n",
    "        - parcel_id\n",
    "        - holding_id\n",
    "        - ranking\n",
    "    \"\"\"\n",
    "    targets_full_df = pd.read_csv(path)\n",
    "    targets_df = targets_full_df[[\"ua_grp_id\", \"target1\"]]\n",
    "    targets = targets_df.set_index('ua_grp_id').T.to_dict('records')[0]\n",
    "    buckets = {}\n",
    "    for id, target in targets.items():\n",
    "        if target > 300:\n",
    "            target = 300\n",
    "        buckets[id] = {'target': target, 'parcels': []}\n",
    "    return buckets\n",
    "\n",
    "def generate_output(buckets):\n",
    "    \"\"\"\n",
    "    Generates an output xlsx file with the following columns:\n",
    "    - bucket_id\n",
    "    - parcel_id\n",
    "    - holding_id\n",
    "    - ranking\n",
    "    - target\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for bucket_id, bucket in buckets.items():\n",
    "        for parcel in bucket['parcels']:\n",
    "            output.append([bucket_id, parcel[\"parcel_id\"], parcel[\"holding_id\"], parcel[\"ranking\"], parcel[\"order_added\"], bucket['target']])\n",
    "    output_df = pd.DataFrame(output, columns=[\"bucket_id\", \"parcel_id\", \"holding_id\", \"ranking\", \"order_added\", \"target\"])\n",
    "\n",
    "    filename = \"output/output_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\") + \".xlsx\"\n",
    "    output_df.to_excel(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row allocation functions\n",
    "\n",
    "Functions that distribute intervention DataFrame information into the buckets dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def buckets_full(buckets):\n",
    "    \"\"\"\n",
    "    Returns True if all buckets are full, False otherwise\n",
    "    \"\"\"\n",
    "    return all(len(bucket['parcels']) >= bucket['target'] for bucket in buckets.values())\n",
    "\n",
    "\n",
    "def check_holding_group_old(holding_group, buckets, added_rows):\n",
    "    \"\"\"\n",
    "    Checks the holding group for parcels that can be added to buckets.\n",
    "    If possible, adds up to 3 parcels from the holding group to buckets.\n",
    "    Adds added rows to the added_rows set, and the holding group to the checked_holdings set.\n",
    "    \"\"\"\n",
    "    counter = 3\n",
    "    for index, holding_row in holding_group.iterrows():\n",
    "        if buckets_full(buckets) or counter == 0:\n",
    "            break\n",
    "        for bucket_id, bucket in buckets.items():\n",
    "            if holding_row[\"intervention_type_id\"] == bucket_id and len(bucket['parcels']) < bucket['target'] and holding_row[\"row_id\"] not in added_rows:\n",
    "                bucket['parcels'].append({\"parcel_id\": holding_row[\"parcel_id\"],\n",
    "                                          \"holding_id\": holding_row[\"holding_id\"],\n",
    "                                          \"ranking\": holding_row[\"ranking\"],\n",
    "                                          \n",
    "                                          })\n",
    "                added_rows.add(holding_row[\"row_id\"])\n",
    "                counter -= 1\n",
    "\n",
    "    return buckets\n",
    "\n",
    "def all_buckets_used_3_times(bucket_counter):\n",
    "    \"\"\"\n",
    "    Returns True if all buckets have been used 3 times, False otherwise.\n",
    "    \"\"\"\n",
    "    return all(value == 3 for value in bucket_counter.values())\n",
    "\n",
    "def check_holding_group(holding_group, buckets, added_rows):\n",
    "    \"\"\"\n",
    "    New version that adds parcels the right (?) way.\n",
    "    \"\"\"\n",
    "    # create a dictionary that has the same keys as buckets, but the values are just zeros\n",
    "    bucket_counter = {key: 0 for key in buckets.keys()}\n",
    "    for index, holding_row in holding_group.iterrows():\n",
    "        if buckets_full(buckets) or all_buckets_used_3_times(bucket_counter):\n",
    "            break\n",
    "        parcel_group = holding_group[holding_group[\"parcel_id\"] == holding_row[\"parcel_id\"]]\n",
    "        buckets, bucket_counter = check_parcel(parcel_group, buckets, added_rows, bucket_counter)\n",
    "\n",
    "    return buckets\n",
    "\n",
    "\n",
    "def check_parcel(parcel_group, buckets, added_rows, bucket_counter=None):\n",
    "    for index, parcel_row in parcel_group.iterrows():\n",
    "        if buckets_full(buckets):\n",
    "            break\n",
    "        for bucket_id, bucket in buckets.items():\n",
    "            \n",
    "                if parcel_row[\"intervention_type_id\"] == bucket_id and len(bucket['parcels']) < bucket['target'] and parcel_row[\"row_id\"] not in added_rows:\n",
    "                    if bucket_counter == None or bucket_counter[bucket_id] < 3:\n",
    "                        bucket['parcels'].append({\"parcel_id\": parcel_row[\"parcel_id\"],\n",
    "                                                \"holding_id\": parcel_row[\"holding_id\"],\n",
    "                                                \"ranking\": parcel_row[\"ranking\"],\n",
    "                                                \"order_added\" : buckets_global_count(buckets)+1,\n",
    "                                                })\n",
    "                        added_rows.add(parcel_row[\"row_id\"])\n",
    "                        bucket_counter[bucket_id] += 1\n",
    "    \n",
    "    return buckets, bucket_counter\n",
    "\n",
    "\n",
    "def iterate_over_interventions(interventions_df, buckets): #, progress_bars):\n",
    "    \"\"\"\n",
    "    Main loop of the script.\n",
    "    Iterates over the rows in the interventions dataframe and adds parcels to the buckets.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Buckets: (\\033[92mgreen\\033[0m = full, \\033[93myellow\\033[0m = still looking for parcels)\")\n",
    "    checked_holdings = set()\n",
    "    added_rows = set()\n",
    "    for index, row in interventions_df.iterrows():\n",
    "        if buckets_full(buckets):\n",
    "            break\n",
    "        if row[\"holding_id\"] not in checked_holdings:\n",
    "            checked_holdings.add(row[\"holding_id\"])\n",
    "            holding_group = interventions_df[interventions_df[\"holding_id\"] == row[\"holding_id\"]]\n",
    "            buckets = check_holding_group(holding_group, buckets, added_rows)\n",
    "        else:\n",
    "            #buckets = check_individual_row(row, buckets, added_rows)\n",
    "            parcel_group = interventions_df[interventions_df[\"parcel_id\"] == row[\"parcel_id\"]]\n",
    "            buckets, bucket_counter = check_parcel(parcel_group, buckets, added_rows)\n",
    "\n",
    "        cosmetics_tools.print_progress(buckets)\n",
    "        # print(dir(cosmetics_tools))\n",
    "        # exit()\n",
    "        #cosmetics_tools.update_progress_bars(buckets, progress_bars)\n",
    "\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions_path = \"input/MT_ua_grp_tiles.csv\"\n",
    "targets_path = \"input/MT_view_target_sample_size.csv\"\n",
    "\n",
    "interventions_df = extract_interventions(interventions_path)\n",
    "buckets = extract_buckets(targets_path)\n",
    "# pbars = cosmetics_tools.show_progress_bars(buckets)\n",
    "\n",
    "iterate_over_interventions(interventions_df, buckets) #, pbars)    \n",
    "\n",
    "# Indicate the reason why the run ended\n",
    "if buckets_full(buckets):\n",
    "    print(\"\\nAll buckets full!\")\n",
    "else:\n",
    "    print(\"\\nSome buckets not full!\")\n",
    "\n",
    "generate_output(buckets)   \n",
    "print(\"\\nOutput file generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main changes:\n",
    "- when looping through a holding, every time a parcel is checked, all interventions from it have to be added to all possible buckets (unless bucket is full)\n",
    "- when looping through holding parcels, stop adding parcels to a bucket if 3 parcels from that holding are already in the bucket. but the other buckets still have to be checked. implement some kind of local bucket list? that is then merged with the big one?\n",
    "\n",
    "- work on the interface a bit\n",
    "- add some parameters\n",
    "\n",
    "\n",
    "---\n",
    "- 3 interventions per bucket\n",
    "\n",
    "\n",
    "- parcel -> check all interventions\n",
    "\n",
    "- holding check -> \n",
    "\n",
    "\n",
    "\n",
    "- once a bucket is filled, maybe remove all rows related to it from the main list?\n",
    "---\n",
    "\n",
    "\n",
    "modifiable parameters: \n",
    "- 3% limit\n",
    "- just the parcels covered by area images or whole list?\n",
    "- priority to the covered?\n",
    "- \n",
    "\n",
    "- costas, augusta, slavko, gilbert, paulo\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 3% rule = for all buckets, if 3% of holdings are added, stop adding to a bucket even if below threshold. if you reach 3% of holdings, only keep adding parcels from the 3% holdings already added\n",
    "- grouping rows together (1 row per parcel with a list of intervensions in one columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
