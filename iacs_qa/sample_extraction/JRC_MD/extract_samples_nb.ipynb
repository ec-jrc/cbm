{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JRC inspection sample selection script\n",
    "\n",
    "Solution that selects inspection samples for the quality assessments (QA) of the Area Monitoring System (AMS) and GeoSpatial Application (GSA) \n",
    "\n",
    "Author: Mateusz Dobrychlop\n",
    "Created on: April 4th 2024\n",
    "\n",
    "Proof of concept version. For now, it does not take into account the 3% constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import cosmetics_tools as cosmetics_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction and output writing functions\n",
    "\n",
    "Processing of two key input files:\n",
    " - the ranked \"interventions\" csv file, that contains rows corresponding to intervention types associated with parcels, which are associated with holdings\n",
    " - the \"targets\" csv file, listing target parcel count for each bucket corresponding to a single intervention type\n",
    "\n",
    " The intervention file is transformed into a DataFrame (filtering out some of its columns) and then used as the main data structure that is iterated over.\n",
    " The intervention DataFrame is sorted by the \"ranking\" column.\n",
    "\n",
    " The targets file is used to create a dictionary that represents buckets, that is gradually populated with info from the intervention DataFrame.\n",
    "\n",
    " This cell also defines a simple function that saves an output excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_interventions(path):\n",
    "    \"\"\"\n",
    "    Extracts the interventions from the csv file and returns a dataframe with the columns:\n",
    "    - parcel_id\n",
    "    - holding_id\n",
    "    - intervention_type_id\n",
    "    - ranking\n",
    "    \"\"\"\n",
    "    interventions_full_df = pd.read_csv(path)\n",
    "    interventions_df = interventions_full_df[[\"gsa_par_id\", \"gsa_hol_id\", \"ua_grp_id\", \"ranking\"]]\n",
    "    interventions_df = interventions_df.sort_values(by=\"ranking\")\n",
    "    interventions_df = interventions_df.rename(columns={\"ua_grp_id\": \"intervention_type_id\", \n",
    "                                                        \"gsa_hol_id\": \"holding_id\", \n",
    "                                                        \"gsa_par_id\": \"parcel_id\"})\n",
    "    \n",
    "    # add a unique row id column that is combination of parcel_id, holding_id and intervention_type_id\n",
    "    # this will be used to identify which rows were already added to buckets\n",
    "    interventions_df['row_id'] = interventions_df['parcel_id'].astype(str) + interventions_df['holding_id'].astype(str) + interventions_df['intervention_type_id'].astype(str)\n",
    "\n",
    "\n",
    "    return interventions_df\n",
    "\n",
    "def extract_buckets(path):\n",
    "    \"\"\"\n",
    "    Extracts the targets from the csv file and returns a dictionary with the keys being the intervention_type_id\n",
    "    and the values being a dictionary with the keys:\n",
    "    - target: the target number of parcels\n",
    "    - parcels: a list of dictionaries with the keys:\n",
    "        - parcel_id\n",
    "        - holding_id\n",
    "        - ranking\n",
    "    \"\"\"\n",
    "    targets_full_df = pd.read_csv(path)\n",
    "    targets_df = targets_full_df[[\"ua_grp_id\", \"target1\"]]\n",
    "    targets = targets_df.set_index('ua_grp_id').T.to_dict('records')[0]\n",
    "    buckets = {}\n",
    "    for id, target in targets.items():\n",
    "        if target > 300:\n",
    "            target = 300\n",
    "        buckets[id] = {'target': target, 'parcels': []}\n",
    "    return buckets\n",
    "\n",
    "def generate_output(buckets):\n",
    "    \"\"\"\n",
    "    Generates an output xlsx file with the following columns:\n",
    "    - bucket_id\n",
    "    - parcel_id\n",
    "    - holding_id\n",
    "    - ranking\n",
    "    - target\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for bucket_id, bucket in buckets.items():\n",
    "        for parcel in bucket['parcels']:\n",
    "            output.append([bucket_id, parcel[\"parcel_id\"], parcel[\"holding_id\"], parcel[\"ranking\"], bucket['target']])\n",
    "    output_df = pd.DataFrame(output, columns=[\"bucket_id\", \"parcel_id\", \"holding_id\", \"ranking\", \"target\"])\n",
    "\n",
    "    filename = \"output/output_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H%M%S\") + \".xlsx\"\n",
    "    output_df.to_excel(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row allocation functions\n",
    "\n",
    "Functions that distribute intervention DataFrame information into the buckets dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buckets_full(buckets):\n",
    "    \"\"\"\n",
    "    Returns True if all buckets are full, False otherwise\n",
    "    \"\"\"\n",
    "    return all(len(bucket['parcels']) >= bucket['target'] for bucket in buckets.values())\n",
    "\n",
    "\n",
    "def check_holding_group(holding_group, buckets, added_rows):\n",
    "    \"\"\"\n",
    "    Checks the holding group for parcels that can be added to buckets.\n",
    "    If possible, adds up to 3 parcels from the holding group to buckets.\n",
    "    Adds added rows to the added_rows set, and the holding group to the checked_holdings set.\n",
    "    \"\"\"\n",
    "    counter = 3\n",
    "    for index, holding_row in holding_group.iterrows():\n",
    "        if buckets_full(buckets) or counter == 0:\n",
    "            break\n",
    "        for bucket_id, bucket in buckets.items():\n",
    "            if holding_row[\"intervention_type_id\"] == bucket_id and len(bucket['parcels']) < bucket['target'] and holding_row[\"row_id\"] not in added_rows:\n",
    "                bucket['parcels'].append({\"parcel_id\": holding_row[\"parcel_id\"],\n",
    "                                          \"holding_id\": holding_row[\"holding_id\"],\n",
    "                                          \"ranking\": holding_row[\"ranking\"],\n",
    "                                          })\n",
    "                added_rows.add(holding_row[\"row_id\"])\n",
    "                counter -= 1\n",
    "\n",
    "    return buckets\n",
    "\n",
    "\n",
    "def check_individual_row(row, buckets, added_rows):\n",
    "    \"\"\"\n",
    "    Checks an individual row for a parcel that can be added to buckets.\n",
    "    This is only done outside of the holding group check, for parcels / rows that are part of a holding\n",
    "    that has already been checked.\n",
    "    \"\"\"\n",
    "    if row[\"row_id\"] not in added_rows:\n",
    "        for bucket_id, bucket in buckets.items():\n",
    "            if row[\"intervention_type_id\"] == bucket_id and len(bucket['parcels']) < bucket['target']:\n",
    "                bucket['parcels'].append({\"parcel_id\": row[\"parcel_id\"],\n",
    "                                        \"holding_id\": row[\"holding_id\"],\n",
    "                                        \"ranking\": row[\"ranking\"],\n",
    "                                        })\n",
    "                added_rows.add(row[\"row_id\"])\n",
    "                \n",
    "    return buckets\n",
    "\n",
    "\n",
    "def iterate_over_interventions(interventions_df, buckets):\n",
    "    \"\"\"\n",
    "    Main loop of the script.\n",
    "    Iterates over the rows in the interventions dataframe and adds parcels to the buckets.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Buckets: (\\033[92mgreen\\033[0m = full, \\033[93myellow\\033[0m = still looking for parcels)\")\n",
    "    checked_holdings = set()\n",
    "    added_rows = set()\n",
    "    for index, row in interventions_df.iterrows():\n",
    "        if buckets_full(buckets):\n",
    "            break\n",
    "\n",
    "        if row[\"holding_id\"] not in checked_holdings:\n",
    "            checked_holdings.add(row[\"holding_id\"])\n",
    "            holding_group = interventions_df[interventions_df[\"holding_id\"] == row[\"holding_id\"]]\n",
    "            buckets = check_holding_group(holding_group, buckets, added_rows)\n",
    "        else:\n",
    "            buckets = check_individual_row(row, buckets, added_rows)\n",
    "\n",
    "        cosmetics_tools.print_progress(buckets)\n",
    "\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets: (\u001b[92mgreen\u001b[0m = full, \u001b[93myellow\u001b[0m = still looking for parcels)\n",
      "\u001b[92m1: 70/70\u001b[0m | \u001b[92m2: 300/300\u001b[0m | \u001b[92m3: 1/1\u001b[0m | \u001b[92m4: 24/24\u001b[0m | \u001b[92m5: 0/0\u001b[0m | \u001b[92m6: 4/4\u001b[0m | \u001b[92m7: 0/0\u001b[0m | \u001b[92m8: 250/250\u001b[0m | \u001b[92m9: 2/2\u001b[0m | \u001b[92m10: 50/50\u001b[0m | \u001b[92m11: 0/0\u001b[0m | \u001b[92m12: 6/6\u001b[0m | \u001b[92m13: 20/20\u001b[0m | \u001b[92m15: 8/8\u001b[0m | \u001b[92m16: 140/140\u001b[0m | \u001b[92m17: 0/0\u001b[0m | \u001b[92m18: 3/3\u001b[0m | \u001b[92m19: 0/0\u001b[0m | \u001b[92m20: 14/14\u001b[0m | \u001b[92m21: 300/300\u001b[0m | \u001b[92m22: 300/300\u001b[0m | \n",
      "All buckets full!\n",
      "\n",
      "Output file generated.\n"
     ]
    }
   ],
   "source": [
    "interventions_path = \"input/MT_ua_grp_tiles.csv\"\n",
    "targets_path = \"input/MT_view_target_sample_size.csv\"\n",
    "\n",
    "interventions_df = extract_interventions(interventions_path)\n",
    "buckets = extract_buckets(targets_path)\n",
    "\n",
    "iterate_over_interventions(interventions_df, buckets)    \n",
    "\n",
    "# Indicate the reason why the run ended\n",
    "if buckets_full(buckets):\n",
    "    print(\"\\nAll buckets full!\")\n",
    "else:\n",
    "    print(\"\\nSome buckets not full!\")\n",
    "\n",
    "generate_output(buckets)   \n",
    "print(\"\\nOutput file generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
